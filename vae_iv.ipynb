{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad für die Dateien\n",
    "import os\n",
    "from models.VAE import VariationalAutoencoder\n",
    "from models.VAE import CustomCallback\n",
    "from models.VAE import step_decay_schedule\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "SECTION = 'vae_sv'\n",
    "RUN_ID = '0002'\n",
    "DATA_NAME = 'digits'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "RUN_FOLDER = os.path.join(\"C:\\Projekte\\dev\\git\\Masterarbeit\", RUN_FOLDER)\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'viz_sv'))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'images_sv'))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'weights_sv'))\n",
    "\n",
    "mode =  'build' #'load' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.VAE import VariationalAutoencoder\n",
    "vae_sv = VariationalAutoencoder(\n",
    "    input_dim = (28,28,1)\n",
    "    , encoder_conv_filters = [32,64,64, 64]\n",
    "    , encoder_conv_kernel_size = [3,3,3,3]\n",
    "    , encoder_conv_strides = [1,2,2,1]\n",
    "    , decoder_conv_t_filters = [64,64,32,1]\n",
    "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
    "    , decoder_conv_t_strides = [1,2,2,1]\n",
    "    , z_dim = 2                                  # Dimension des Latent Spaces\n",
    ")\n",
    "\n",
    "if mode == 'build':\n",
    "    RUN_FOLDER = 'run/vae_sv/0002_digits/viz_sv/viz'\n",
    "    vae_sv.save(RUN_FOLDER)\n",
    "else:\n",
    "    vae_sv.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_sv.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_sv.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import numpy as np\n",
    "import numpy.matlib as npm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "dat = np.loadtxt('HestonTrainSet_ivol_201_neu_klein.txt')     # Trainieren auf den Prices/Impliziten Volatiltäten\n",
    "NModelPar = 5                                    # Anzahl der Heston Parameter\n",
    "\n",
    "yy=dat[:len(dat),:NModelPar]                             # Model Parameter für die Trainingsdaten \n",
    "xx=dat[:len(dat),NModelPar:]                             # Output Daten (Prices/Impliziten Volatiltäten)\n",
    "print(xx.shape)\n",
    "print(yy.shape)\n",
    "\n",
    "strikes=np.array([0.500000000000000, 0.537037037037037, 0.574074074074074, 0.611111111111111, 0.648148148148148, \n",
    "                  0.685185185185185, 0.722222222222222, 0.759259259259259, 0.796296296296296, 0.833333333333333,\n",
    "                  0.870370370370370, 0.907407407407407, 0.944444444444444, 0.981481481481481, 1.01851851851852,\n",
    "                  1.05555555555556,  1.09259259259259,  1.12962962962963,  1.16666666666667, 1.20370370370370,\n",
    "                  1.24074074074074, 1.27777777777778, 1.31481481481481, 1.35185185185185,   1.38888888888889,\n",
    "                  1.42592592592593, 1.46296296296296, 1.50000000000000])                \n",
    "\n",
    "maturities=np.array([0.500000, 0.851852, 1.203704, 1.555556, 1.907407, 2.259259, 2.611111, 2.962963, 3.314815, \n",
    "                     3.666667,4.018519, 4.370370, 4.722222, 5.074074, 5.425926, 5.777778, 6.129630, 6.481481, \n",
    "                     6.833333, 7.185185, 7.537037, 7.888889, 8.240741, 8.592593, 8.944444, 9.296296, 9.648148,\n",
    "                     10.000000])\n",
    "\n",
    "weights = np.array([0.1,0.1,0.1,1.0,1.0,1.0,1.0,1.0,0.1,0.1,0.1])\n",
    "cw = np.ndarray.flatten(npm.repmat(weights,8,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalex = StandardScaler()\n",
    "\n",
    "xx_transform = scalex.fit_transform(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_scaled, x_test_scaled, x_train,x_test,y_train, y_test = train_test_split(\n",
    "    xx_transform, xx, yy, test_size=0.15, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zufällige Surfaces der Inpudaten ausgeben\n",
    "\n",
    "n_to_show = 17\n",
    "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
    "testsurf = np.reshape(xx,(len(xx),28,28,1))\n",
    "example_surface = testsurf[example_idx]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(n_to_show):\n",
    "    img = example_surface[i].squeeze()\n",
    "    sub = fig.add_subplot(2, n_to_show, i+1)\n",
    "    sub.axis('off')\n",
    "          \n",
    "    sub.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "ax = fig.gca(projection='3d')\n",
    "for i in range(n_to_show):\n",
    "    ax.plot_surface(strikes, maturities, testsurf[i,:,:,0], cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "sub.imshow(img, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape für das Nutzen von CNN mit dem Autoencoder\n",
    "x_train_scaled_reshape = np.reshape(x_train_scaled,(len(x_train),28,28,1))\n",
    "x_test_scaled_reshape = np.reshape(x_test_scaled,(len(x_test),28,28,1))\n",
    "\n",
    "x_train_reshape = np.reshape(x_train,(len(x_train),28,28,1))\n",
    "x_test_reshape = np.reshape(x_test,(len(x_test),28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kompilieren & Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "R_LOSS_FACTOR = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_sv.compile(LEARNING_RATE, R_LOSS_FACTOR, alpha=1.0, beta=1.0)\n",
    "\n",
    "# beta-VAE\n",
    "#vae_sv.compile(LEARNING_RATE, R_LOSS_FACTOR, alpha=1.0, beta=4.0)\n",
    "\n",
    "#vae_sv.compile(LEARNING_RATE, R_LOSS_FACTOR, alpha=0.0, beta=1.0)\n",
    "#vae_sv.compile(LEARNING_RATE, R_LOSS_FACTOR, alpha=0.1, beta=0.9)\n",
    "#vae_sv.compile(LEARNING_RATE, R_LOSS_FACTOR, alpha=0.3, beta=0.7)\n",
    "#vae_sv.compile(LEARNING_RATE, R_LOSS_FACTOR, alpha=0.5, beta=0.5)\n",
    "#vae_sv.compile(LEARNING_RATE, R_LOSS_FACTOR, alpha=0.7, beta=0.3)\n",
    "#vae_sv.compile(LEARNING_RATE, R_LOSS_FACTOR, alpha=0.9, beta=0.1)\n",
    "#vae_sv.compile(LEARNING_RATE, R_LOSS_FACTOR, alpha=1.0, beta=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae_sv.train(     \n",
    "    x_train_reshape\n",
    "    , batch_size = BATCH_SIZE\n",
    "   , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekonstruktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zufällige Rekonstruktion\n",
    "\n",
    "n_to_show = 16\n",
    "\n",
    "example_idx = np.random.choice(range(len(x_test)), n_to_show) # generiere zufällige ID's\n",
    "#example_idx = [2,39,705,69,81,912,306,1210,1031,341,1314,670,624,352,293,486]  # für Vergleich mit AE\n",
    "\n",
    "example_surface = x_test[example_idx] # (zufälligen) Surfaces\n",
    "example_surface = np.reshape(example_surface,(len(example_surface),28,28,1))\n",
    "\n",
    "z_points = vae_sv.encoder.predict(example_surface) # z_points auf denen die (zufälligen) Surfaces gespeichert sind\n",
    "\n",
    "reconst_images = vae_sv.decoder.predict(z_points) # vom VAE rekonstruierte Surfaces \n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(n_to_show): # originale Surfaces\n",
    "    img = example_surface[i].squeeze()\n",
    "    sub = fig.add_subplot(2, n_to_show, i+1)\n",
    "    sub.axis('off')\n",
    "    sub.text(0.5, -0.35, str(np.round(z_points[i],1)), fontsize=10, ha='center', transform=sub.transAxes)         \n",
    "    sub.imshow(img)\n",
    "\n",
    "for i in range(n_to_show): # rekonstruierte Surfaces\n",
    "    img = reconst_images[i].squeeze()\n",
    "    sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
    "    sub.axis('off')\n",
    "    sub.imshow(img, cmap='coolwarm')\n",
    "    \n",
    "#fig.savefig('C:\\\\Users\\\\staeding\\\\Desktop\\\\Masterarbeit_neu\\\\VAE_neu\\\\Rek3D_zufaellig') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rekonstruktion von Surfaces auf einem bestimmten Grid\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "n_to_show = 17\n",
    "\n",
    "example_surface = x_test                                       # erstmal alle Surfaces abspeichern\n",
    "example_surface = np.reshape(example_surface,(len(example_surface),28,28,1))\n",
    "\n",
    "z_points = vae_sv.encoder.predict(example_surface)               # z_points auf denen die alles Surfaces gespeichert sind\n",
    "\n",
    "\n",
    "df = pd.DataFrame(np.round(z_points,1))                      \n",
    "df.to_excel('z_points_VAE.xlsx')                     # speicher die z_points gerundet auf eine Nachkommastelle in eine Excel ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid mit fixer x-Kooridante \n",
    "# Kooridanten mit den jeweiligen Indexe extrahiert mit Excel (nicht elegant, aber effektiv)\n",
    "\n",
    "z_points_grid = np.array([[0.0, -1.0],[0.0, -0.9],[0.0, -0.8],[0.0, -0.6],[0.0, -0.5],[0.0, -0.4],[0.0, -0.3],[0.0, -0.2],\n",
    "                         [0.0, -0.1],[0.0, 0.0],[0.0, 0.1],[0.0, 0.3],[0.0, 0.5],[0.0, 0.6],[0.0, 0.7],[0.0, 0.9],[0.0, 1.0]])\n",
    "\n",
    "idx = [1268,583,193,418,1175,1076,872,1147,590,547,859,972,107,898,867,587,1353]\n",
    "\n",
    "example_surfaces_grid = np.zeros([n_to_show,28,28,1])\n",
    "for i in range(len(idx)):\n",
    "    example_surfaces_grid[i] = example_surface[idx[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid mit fixer y-Kooridante \n",
    "# Kooridanten mit den jeweiligen Indexe extrahiert mit Excel (nicht elegant, aber effektiv)\n",
    "\n",
    "z_points_grid = np.array([[-0.9, 0.0],[-0.8, 0.0],[-0.7, 0.0],[-0.5, 0.0],[-0.4, 0.0],[-0.3, 0.0],[-0.2, 0.0],[-0.1, 0.0],\n",
    "                         [0, 0.0],[0.1, 0.0],[0.2, 0.0],[0.3, 0.0],[0.4, 0.0],[0.5, 0.0],[0.6, 0.0],[0.7, 0.0],[0.9, 0.0]])\n",
    "\n",
    "idx = [24,209,970,1307,424,1456,1295,681,547,1299,1144,1073,253,1303,1138,1230,351]\n",
    "\n",
    "example_surfaces_grid = np.zeros([n_to_show,28,28,1])\n",
    "for i in range(len(idx)):\n",
    "    example_surfaces_grid[i] = example_surface[idx[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid mit fixer z-Kooridante \n",
    "# Kooridanten mit den jeweiligen Indexe extrahiert mit Excel (nicht elegant, aber effektiv)\n",
    "\n",
    "z_points_grid = np.array([[-1.2, -0.3, 0.0],[-1.1, -0.4, 0.0],[-1.0, 1.7, 0.0],[-0.7, -0.5, 0.0],\n",
    "                          [-0.6, 1.2, 0.0],[-0.5, -1.8, 0.0],[-0.3, -0.1, 0.0],[-0.1, 0.2, 0.0],[0.0, 1.7, 0.0],\n",
    "                          [0.1, 0.8, 0.0],[0.2, -2.1, 0.0],[0.3, 0.4, 0.0],[0.4, 0.9, 0.0],[0.8, 1.0, 0.0],\n",
    "                          [0.9, 0.5, 0.0],[1.0, -0.8, 0.0],[1.5, -0.1, 0.0]])\n",
    "\n",
    "idx = [1402,945,1119,42,1280,868,1057,958,1437,1265,187,1403,1468,1483,670,891,1430]\n",
    "\n",
    "example_surfaces_grid = np.zeros([n_to_show,28,28,1])\n",
    "for i in range(len(idx)): # speichere die Surfaces auf dem Grid ab\n",
    "    example_surfaces_grid[i] = example_surface[idx[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rekonstruktion auf einem bestimmten Grid\n",
    "\n",
    "n_to_show = 17\n",
    "\n",
    "reconst_images = vae_sv.decoder.predict(z_points_grid)                # vom VAE rekonstruierte Surfaces auf dem Grid\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(n_to_show): # originale Surfaces\n",
    "    img = example_surfaces_grid[i].squeeze()     \n",
    "    sub = fig.add_subplot(2, n_to_show, i+1)\n",
    "    sub.axis('off')\n",
    "    sub.text(0.5, -0.35, str(z_points_grid[i]), fontsize=10, ha='center', transform=sub.transAxes)         \n",
    "    sub.imshow(img)\n",
    "    \n",
    "    \n",
    "for i in range(n_to_show): #  rekonstruierte Surfaces\n",
    "    img = reconst_images[i].squeeze()\n",
    "    sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
    "    sub.axis('off')\n",
    "    c = sub.imshow(img, cmap='coolwarm')#gray_r')\n",
    "    \n",
    "#    fig.colorbar(c, ax = sub) \n",
    "fig.savefig('Rek_VAE_Fix') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot des gesamten Verlustes\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('C:\\\\Projekte\\\\dev\\\\git\\\\Masterarbeit\\\\RE1.0_KL1.0_VAE\\\\log.csv', sep=';')\n",
    "print(df)\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.plot(df['epoch'], df['loss'], ls='-')\n",
    "plt.title('Loss AE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Trainingsloss'])\n",
    "plt.savefig('LossVAE.png')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gibt den Latent Space mit n_to_show Punkten aus \n",
    "\n",
    "n_to_show = 5000\n",
    "figsize = 12\n",
    "\n",
    "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
    "example_images = x_test[example_idx]\n",
    "example_labels = y_test[example_idx]\n",
    "\n",
    "z_points = vae_sv.encoder.predict(x_test_scaled_reshape[example_idx])\n",
    "\n",
    "min_x = min(z_points[:, 0])\n",
    "max_x = max(z_points[:, 0])\n",
    "min_y = min(z_points[:, 1])\n",
    "max_y = max(z_points[:, 1])\n",
    "#min_t = min(z_points[:, 2])          # für 3D\n",
    "#max_t = max(z_points[:, 2])          # für 3D\n",
    "\n",
    "# für 2D\n",
    "plt.figure(figsize=(figsize, figsize))\n",
    "plot = plt.scatter(z_points[:, 0] , z_points[:, 1], c='black', alpha=0.5, s=2)\n",
    "plt.show()\n",
    "fig = plot.get_figure()\n",
    "fig.savefig('LatentSpace2D.png')\n",
    "\n",
    "\n",
    "# für 3D\n",
    "#fig = plt.figure(figsize=(15, 15))\n",
    "#ax = fig.add_subplot(projection='3d')\n",
    "#for i in range(n_to_show):\n",
    "#    ax.scatter(z_points[:, 0], z_points[:, 1], z_points[:, 2], cmap=cm.coolwarm,\n",
    "#                       linewidth=0, antialiased=False, c='black')\n",
    "#ax.set_title('Latent Space in 3D')\n",
    "#ax.set_xlabel('Z1')\n",
    "#ax.set_ylabel('Z2')\n",
    "#ax.set_zlabel('Z3')\n",
    "#sub.imshow(img, cmap='gray_r')\n",
    "#fig.savefig('LatentSpace3D.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gibt Zufallsvariablen/Punkte x des Latent Spaces aus und vergleicht diese mit der Standardnormalverteilung\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "plot = sns.distplot(z_points[:, 0], hist=True, kde=True, \n",
    "             bins=25, color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4})\n",
    "x = np.linspace(0 - 3*1, 0 + 3*1, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, 0, 1), color='red')\n",
    "fig = plot.get_figure()\n",
    "#fig.savefig('LatentSpace1_NormalDist') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gibt Zufallsvariablen/Punkte y des Latent Spaces aus und vergleicht diese mit der Standardnormalverteilung\n",
    "\n",
    "plot = sns.distplot(z_points[:, 1], hist=True, kde=True, \n",
    "             bins=25, color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4})\n",
    "x = np.linspace(0 - 3*1, 0 + 3*1, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, 0, 1), color='red')\n",
    "fig = plot.get_figure()\n",
    "#fig.savefig('LatentSpace2_NormalDist') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gibt Zufallsvariablen/Punkte z des Latent Spaces aus und vergleicht diese mit der Standardnormalverteilung\n",
    "\n",
    "plot = sns.distplot(z_points[:, 2], hist=True, kde=True, \n",
    "             bins=25, color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4})\n",
    "x = np.linspace(0 - 3*1, 0 + 3*1, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, 0, 1), color='red')\n",
    "fig = plot.get_figure()\n",
    "#fig.savefig('LatentSpace3_NormalDist') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weitere Analysen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = 8\n",
    "plt.figure(figsize=(figsize, figsize))\n",
    "plt.scatter(z_points[:, 0] , z_points[:, 1], c='black', alpha=0.5, s=2)\n",
    "\n",
    "\n",
    "grid_size = 15\n",
    "grid_depth = 2\n",
    "figsize = 15\n",
    "\n",
    "x = np.random.normal(size = grid_size * grid_depth)\n",
    "y = np.random.normal(size = grid_size * grid_depth)\n",
    "\n",
    "z_grid = np.array(list(zip(x, y)))\n",
    "reconst = vae_sv.decoder.predict(z_grid)\n",
    "\n",
    "plt.scatter(z_grid[:, 0] , z_grid[:, 1], c = 'red', alpha=1, s=20)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(figsize, grid_depth))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(grid_size*grid_depth):\n",
    "    ax = fig.add_subplot(grid_depth, grid_size, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, str(np.round(z_grid[i],1)), fontsize=8, ha='center', transform=ax.transAxes)\n",
    "    \n",
    "    ax.imshow(reconst[i, :,:,0], cmap = 'coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "n_to_show = 500\n",
    "grid_size = 15\n",
    "fig_height = 7\n",
    "fig_width = 15\n",
    "\n",
    "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
    "example_images = x_test_reshape[example_idx]\n",
    "example_labels = y_test[example_idx]\n",
    "\n",
    "z_points = vae_sv.encoder.predict(example_images)\n",
    "p_points = norm.cdf(z_points)\n",
    "\n",
    "fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "#plot_1 = ax.scatter(z_points[:, 0] , z_points[:, 1] , cmap='rainbow' , c= example_labels , alpha=0.5, s=2)\n",
    "plot_1 = ax.scatter(z_points[:, 0] , z_points[:, 1] , cmap='rainbow' , alpha=0.5, s=2)\n",
    "plt.colorbar(plot_1)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "#plot_2 = ax.scatter(p_points[:, 0] , p_points[:, 1] , cmap='rainbow' , c= example_labels, alpha=0.5, s=5)\n",
    "plot_2 = ax.scatter(p_points[:, 0] , p_points[:, 1] , cmap='rainbow' , alpha=0.5, s=5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_show = 5000\n",
    "grid_size = 20\n",
    "figsize = 8\n",
    "\n",
    "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
    "example_images = x_test_reshape[example_idx]\n",
    "example_labels = y_test[example_idx]\n",
    "\n",
    "z_points = vae_sv.encoder.predict(example_images)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(z_points[:, 0] , z_points[:, 1] , cmap='rainbow' #, c= example_labels\n",
    "            , alpha=0.5, s=2)\n",
    "plt.colorbar()\n",
    "\n",
    "x = norm.ppf(np.linspace(0.01, 0.99, grid_size))\n",
    "y = norm.ppf(np.linspace(0.01, 0.99, grid_size))\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "xv = xv.flatten()\n",
    "yv = yv.flatten()\n",
    "z_grid = np.array(list(zip(xv, yv)))\n",
    "\n",
    "reconst = vae_sv.decoder.predict(z_grid)\n",
    "\n",
    "plt.scatter(z_grid[:, 0] , z_grid[:, 1], c = 'black'#, cmap='rainbow' , c= example_labels\n",
    "            , alpha=1, s=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(figsize, figsize))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "for i in range(grid_size**2):\n",
    "    ax = fig.add_subplot(grid_size, grid_size, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(reconst[i, :,:,0], cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
