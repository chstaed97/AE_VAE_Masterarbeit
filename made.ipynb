{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6ggsAVn5Bc-4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import io as sio\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import gzip\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from data import mnist\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qHoMwb3CCDu6"
   },
   "outputs": [],
   "source": [
    "# Mask dense\n",
    "class MaskedLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias = True):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "        self.register_buffer('mask', torch.ones(out_features, in_features))\n",
    "    def set_mask(self, mask):\n",
    "        self.mask.data.copy_(torch.from_numpy(mask.astype(np.uint8).T))\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.mask * self.weight, self.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pZwQiPS0CGsT"
   },
   "outputs": [],
   "source": [
    "# MADE architecture\n",
    "class MADEnet(nn.Module):\n",
    "    def __init__(self, nin, hidden_sizes, nout, ordering, num_masks):\n",
    "        super().__init__()\n",
    "        self.nin = nin\n",
    "        self.nout = nout\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        assert self.nout % self.nin  == 0\n",
    "        \n",
    "        self.net = []\n",
    "        hs = [nin] + hidden_sizes + [nout]\n",
    "        for h0, h1 in zip(hs, hs[1:]):\n",
    "            self.net.extend([\n",
    "                MaskedLinear(h0, h1),\n",
    "                nn.ReLU()])\n",
    "        self.net.pop()\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "        \n",
    "        self.num_masks = num_masks\n",
    "        self.seed = 16\n",
    "        \n",
    "        self.m = {}\n",
    "        self.m[-1] = ordering\n",
    "         \n",
    "        self.direct = MaskedLinear(self.nin, self.nout)\n",
    "        mask_direct = self.m[-1][:,None] < self.m[-1][None,:]\n",
    "        mask_direct = np.array(mask_direct)\n",
    "        print(mask_direct.shape)\n",
    "        self.direct.set_mask(mask_direct)\n",
    "\n",
    "        self.update_masks()\n",
    "        \n",
    "    def update_masks(self):\n",
    "        if len(self.m) != 1 and self.num_masks == 1: \n",
    "            return\n",
    "        L = len(self.hidden_sizes)\n",
    "        \n",
    "        # 1 seed -> 1 mask =>> update seed\n",
    "        rng = np.random.RandomState(self.seed)\n",
    "        self.seed = (self.seed + 1) % self.num_masks\n",
    "        \n",
    "        # random m in hidden layers\n",
    "        for l in range(L):\n",
    "            self.m[l] = rng.randint(self.m[l-1].min(), self.nin - 1, size = self.hidden_sizes[l])\n",
    "        \n",
    "        # construct masks\n",
    "        masks = [self.m[l-1][:,None] <= self.m[l][None,:] for l in range(L)]\n",
    "        masks.append(self.m[L-1][:,None] < self.m[-1][None, :])\n",
    "        \n",
    "        # use for other output distributions \n",
    "        if self.nout > self.nin:\n",
    "            k = int(self.nout / self.nin)\n",
    "            masks[-1] = np.concatenate([masks[-1]]*k, axis = 1)\n",
    "            \n",
    "        layers = [l for l in self.net.modules() if isinstance(l, MaskedLinear)]\n",
    "        for l, m in zip(layers,  masks):\n",
    "            l.set_mask(m)\n",
    "\n",
    "  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        #return self.net(x) + self.direct(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sznRu3UoXd7H"
   },
   "outputs": [],
   "source": [
    "class MADE():\n",
    "    def __init__(self, hiddens='1024', num_masks=1, ordering='raster-scan', \n",
    "               samples=1, resample_every=20, data='mnist', imgshape = (28,28,1)):\n",
    "    # tunning params\n",
    "        self.hiddens = hiddens\n",
    "        self.num_masks = num_masks\n",
    "        self.ordering = ordering \n",
    "        self.samples = samples\n",
    "        self.resample_every = resample_every\n",
    "        self.data_path_vol = 'C:\\Projekte\\dev\\git\\Masterarbeit\\\\'\n",
    "        self.data_path_faces = 'C:\\\\Projekte\\\\dev\\\\git\\\\Masterarbeit\\\\MADE\\\\'\n",
    "        self.data_path_binmnist = 'C:\\\\Projekte\\\\dev\\\\git\\\\Masterarbeit\\\\made-master\\\\made-master\\\\data\\\\binarized_mnist.npz'\n",
    "        self.data_path_mnist = 'C:\\\\Projekte\\\\dev\\\\git\\\\Masterarbeit\\\\made-master\\\\made-master\\\\data\\\\mnist.npz'\n",
    "        self.data_path_emnist = '/content/drive/My Drive/datasets/emnist-letters.mat'\n",
    "        self.data_path_shape = '/content/drive/My Drive/datasets/shapes/data.npy'\n",
    "        self.imgshape = imgshape\n",
    "        np.random.seed(16)\n",
    "        torch.manual_seed(16)\n",
    "        torch.cuda.manual_seed_all(16)\n",
    "\n",
    "        # loading data\n",
    "        print(\"Loading data ...\")\n",
    "        if data == 'vol':\n",
    "            print(\"Dataset Volatility\")\n",
    "            self.load_data_vol()\n",
    "        elif data == 'faces':\n",
    "            print(\"Dataset Faces\")\n",
    "            self.load_data_faces()\n",
    "        elif data =='emnist':\n",
    "            print(\"Dataset EMNIST\")\n",
    "            self.load_data_emnist()\n",
    "        elif data =='mnist':\n",
    "            print(\"Dataset MNIST\")\n",
    "            self.load_data_mnist()        \n",
    "        elif data =='binmnist':\n",
    "            print(\"Dataset Binarized MNIST\")\n",
    "            self.load_data_binmnist()\n",
    "        elif data =='shape':\n",
    "            print(\"Dataset SHAPE\")\n",
    "            self.load_data_shape()\n",
    "        print(\"Loading data done\")\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # Construct mode and ship to GPU\n",
    "        print(\"Constructing MADE architecture ...\")\n",
    "\n",
    "        hidden_list = list(map(int, self.hiddens.split(',')))\n",
    "\n",
    "          #create order\n",
    "        if self.ordering == 'raster-scan':\n",
    "            self.order = np.arange(self.xtr.size(1))\n",
    "        elif self.ordering =='columns':\n",
    "            a = np.arange(0, self.xtr.size(1)).reshape(self.imgshape)\n",
    "            x = a.T\n",
    "            self.order = x.reshape(self.xtr.size(1))\n",
    "        elif self.ordering == 'randoms':\n",
    "            self.order = np.random.RandomState(16).permutation(self.xtr.size(1))\n",
    "        elif self.ordering == 'reverseRS':\n",
    "            self.order = np.arange(self.xtr.size(1))[::-1]\n",
    "        elif self.ordering == 'top_down_mid':\n",
    "            l = self.xtr.size(1)\n",
    "            top = np.arange(self.xtr.size(1))\n",
    "            down = top[l//2:][::-1]\n",
    "            self.order = np.concatenate([top[:l//2], down])\n",
    "\n",
    "        self.model = MADEnet(nin = self.xtr.size(1), hidden_sizes=hidden_list, \n",
    "                             nout=self.xtr.size(1), ordering=self.order, num_masks=self.num_masks)\n",
    "        self.model.cuda()\n",
    "\n",
    "        #set up the optimizer\n",
    "        self.opt = torch.optim.Adam(self.model.parameters(), 1e-3, weight_decay=1e-4)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.opt, step_size=45, gamma=0.1)\n",
    "        print(\"Constructing MADE architecture done\")\n",
    "        print(\"------------------------------\")\n",
    "   \n",
    "    def reconstruct(self, n):\n",
    "        rng = np.random.randint(low = 0, high = self.xtr.size(0), size = n, dtype=int)\n",
    "        l = self.xtr.size(1)\n",
    "        origin = [self.xtr[i].tolist() for i in rng]\n",
    "        origin = np.array(origin).astype(np.float32)\n",
    "        origin_all = [self.xtr[i].tolist() for i in rng]\n",
    "        origin_all = np.array(origin_all).astype(np.float32)\n",
    "        deconstruct = origin\n",
    "        deconstruct[:,l//2:] = 0\n",
    "        x  = torch.from_numpy(deconstruct).cuda()\n",
    "        x = x.reshape(n,28*28)\n",
    "        samples  = torch.from_numpy(deconstruct).cuda()\n",
    "        samples = x.reshape(n,28*28)\n",
    "        #example_surface = np.reshape(origin,(len(x),28,28,1))\n",
    "        #print(example_surface.shape)\n",
    "        mu = torch.zeros(n, 784).cuda()\n",
    "        var = torch.ones(n, 784).cuda()\n",
    "        with torch.no_grad():\n",
    "            eps = samples.clone().normal_(0, 1)\n",
    "            for i in range(l//2 + 1, l, 1):\n",
    "                logits = self.model(x)[:,i].cuda()\n",
    "                #print(logits)\n",
    "                probs = torch.sigmoid(logits).cuda()\n",
    "                #print(probs)\n",
    "                x[:,i] = torch.bernoulli(probs)\n",
    "                #x[:,i] = torch.binomial(torch.tensor(784.0).cuda(), probs)\n",
    "                #print(x[:,i])\n",
    "                #x[:,i] = torch.normal(mu[:,i], var[:,i])\n",
    "                #x[:, i] = mu[:, i] + torch.exp(var[:, i]) * eps[:, i]\n",
    "            \n",
    "                #samples[:, i] = (torch.sigmoid(samples[:, i]) - 1e-6) / (1 - 2e-6)\n",
    "                #samples[:, i] = samples[:, i].detach().cpu().view(n, 28, 28)\n",
    "                #x[:,i] = samples[:,i]\n",
    "            x = x.view(n, self.xtr.size(1))\n",
    "            #x = x.view(n, 28*28)\n",
    "        #origin_all = np.reshape(origin_all,(len(origin_all),28,28,1))\n",
    "        #origin = np.reshape(origin,(len(origin),28,28,1))\n",
    "        x = np.array(x.tolist()).astype(np.float32) \n",
    "        #x = np.reshape(x,(len(x),28,28,1))\n",
    "        return origin_all, origin, x\n",
    "        #return origin_all, origin, np.array(x.tolist()).astype(np.float32) \n",
    "    \n",
    "\n",
    "    def sample(self, n, resample = True):\n",
    "        noise = torch.rand(n, self.xtr.size(1)).cuda()\n",
    "        samples = self.samples if resample else 1\n",
    "        with torch.no_grad():\n",
    "            for i in self.order:\n",
    "                logits = torch.zeros(n).cuda()\n",
    "                # resampling\n",
    "                for s in range(samples):\n",
    "                        logits += self.model(noise)[:, i]\n",
    "                logits = logits / samples\n",
    "                probs = torch.sigmoid(logits)\n",
    "                noise[:, i] = torch.bernoulli(probs)\n",
    "            noise = noise.view(n, self.xtr.size(1))\n",
    "        return np.array(noise.tolist()).astype(np.int32)\n",
    "  \n",
    "    def get_nearest_real_images(self, xfake):\n",
    "        # Kneighbor algo for comparing\n",
    "        self.nrnb = NearestNeighbors(n_neighbors= 1, p=2)\n",
    "        self.nrnb.fit(self.xtr.tolist())\n",
    "        indices = self.nrnb.kneighbors(xfake, return_distance=False)\n",
    "        tmp = self.xtr.tolist()\n",
    "        xnearest = [tmp[i[0]] for i in indices]\n",
    "        xnearest = np.array(xnearest).astype(np.int32)\n",
    "        return xnearest\n",
    "\n",
    "    def gen_fake_and_save(self, filename, resample):\n",
    "        xfake = self.sample(100, resample= resample)\n",
    "        fig=plt.figure(figsize=(8, 8))\n",
    "        columns = 10\n",
    "        rows = 10\n",
    "        for i in range(1, columns*rows +1):\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(xfake[i-1].reshape(self.imgshape), cmap ='gray')\n",
    "        #plt.savefig(filename)\n",
    "        plt.show()\n",
    "\n",
    "    def training(self, epochs, batch_size):\n",
    "        path = \"C:\\\\Projekte\\\\dev\\\\git\\\\\"\n",
    "        self.batch_size = batch_size\n",
    "        self.test_loss = []\n",
    "        self.train_loss = []\n",
    "        print(\"Start training\")\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch %d\" % (epoch, ))\n",
    "            self.scheduler.step(epoch)\n",
    "            te_loss = self.run_epoch('test', upto= 5)\n",
    "            tr_loss = self.run_epoch('train')\n",
    "            self.test_loss.append(te_loss)\n",
    "            self.train_loss.append(tr_loss)\n",
    "            #if epoch % 10 == 0 or epoch + 1 == epochs:\n",
    "                #filename = \"epoch\"+str(epoch)+\".png\";\n",
    "                #self.gen_fake_and_save(path+filename, False)\n",
    "        print(\"Training done\")\n",
    "  \n",
    "    def load_data_vol(self):\n",
    "        dat = np.loadtxt(self.data_path_vol + 'HestonTrainSet_ivol_201_neu_klein.txt')\n",
    "        NModelPar = 5 \n",
    "        yy=dat[:len(dat),:NModelPar]                           \n",
    "        xx=dat[:len(dat),NModelPar:] \n",
    "        \n",
    "        #scalex = StandardScaler()\n",
    "\n",
    "        #xx_transform = scalex.fit_transform(xx)\n",
    "        #x_train, x_test, y_train, y_test = train_test_split(xx_transform, yy, test_size=0.33, random_state=42)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(xx, yy, test_size=0.33, random_state=42)\n",
    "        \n",
    "        x_train = np.reshape(x_train,(len(x_train),28*28))\n",
    "        print(x_train.shape)\n",
    "        x_test = np.reshape(x_test,(len(x_test),28*28))\n",
    "        print(x_test.shape)\n",
    "\n",
    "        x_train = x_train.astype(np.float32)\n",
    "        x_test = x_test.astype(np.float32)\n",
    "        self.xtr = torch.from_numpy(x_train).cuda()\n",
    "        self.xte = torch.from_numpy(x_test).cuda()\n",
    "\n",
    "    def load_data_faces(self):\n",
    "        # Download Olivetti faces dataset\n",
    "        olivetti = fetch_olivetti_faces()\n",
    "        x = olivetti.images\n",
    "        y = olivetti.target\n",
    "        X = x.reshape((400, 4096))\n",
    "        X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "        x_train = X_train.astype(np.float32)\n",
    "        x_test = X_test.astype(np.float32)\n",
    "        self.xtr = torch.from_numpy(x_train).cuda()\n",
    "        self.xte = torch.from_numpy(x_test).cuda()\n",
    "    \n",
    "    def load_data_shape(self):\n",
    "        X = np.load(self.data_path_shape)\n",
    "        indices = np.arange(0, X.shape[0])\n",
    "        random.shuffle(indices)\n",
    "        X = X[indices].astype(np.float32)\n",
    "        l = 1600\n",
    "        xtr, xte = X[indices[:l]], X[indices[l:]]\n",
    "                 \n",
    "        self.xtr = torch.from_numpy(xtr).cuda()\n",
    "        self.xte = torch.from_numpy(xte).cuda()\n",
    "\n",
    "    def load_data_binmnist(self):\n",
    "        binmnist = np.load(self.data_path_binmnist)\n",
    "        self.xtr, self.xte = binmnist['train_data'], binmnist['valid_data']\n",
    "        self.xtr = torch.from_numpy(self.xtr).cuda()\n",
    "        self.xte = torch.from_numpy(self.xte).cuda()\n",
    "  \n",
    "    def load_data_mnist(self):\n",
    "        mnist_ = mnist.MNIST()\n",
    "        train, val, _ = mnist_.get_data_splits()\n",
    "        #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        #train = min_max_scaler.fit_transform(train)\n",
    "        #val = min_max_scaler.fit_transform(val)\n",
    "        #train = torch.from_numpy(train)\n",
    "        #val = torch.from_numpy(val)\n",
    "        self.xtr, self.xte = train, val\n",
    "        self.xtr = train.cuda()\n",
    "        self.xte = val.cuda()\n",
    "\n",
    "   \n",
    "    def load_data_emnist(self):\n",
    "        mat = sio.loadmat(self.data_path_emnist)\n",
    "        data = mat['dataset']\n",
    "        X_train = data['train'][0,0]['images'][0,0]\n",
    "        X_test = data['test'][0,0]['images'][0,0]\n",
    "        X_train = X_train.reshape(X_train.shape[0], 28, 28, order=\"F\")\n",
    "        X_test = X_test.reshape(X_test.shape[0], 28, 28 , order=\"F\")\n",
    "        X_train = X_train.reshape(X_train.shape[0], 784, order='C').astype(np.float32)\n",
    "        X_test = X_test.reshape(X_test.shape[0], 784, order='C').astype(np.float32)\n",
    "        X_train = np.round(X_train / 255.)\n",
    "        X_test = np.round(X_test/ 255.)\n",
    "        self.xtr = torch.from_numpy(X_train).cuda()\n",
    "        self.xte = torch.from_numpy(X_test).cuda()\n",
    "    \n",
    "    def run_epoch(self, split, upto = None):\n",
    "        torch.set_grad_enabled(split == 'train')\n",
    "        if split == 'train': self.model.train()\n",
    "        else: self.model.eval()\n",
    "    \n",
    "        x = self.xtr if split == 'train' else self.xte\n",
    "        samples = 1 if split == 'train' else self.samples\n",
    "        x = x.reshape(-1, 28 * 28)\n",
    "        N,D = x.size()\n",
    "        B = self.batch_size\n",
    "        nsteps = N//B if upto is None else min(N//B, upto)\n",
    "        lossfs = []\n",
    "        # An epoch has many batches\n",
    "        for step in range(nsteps):\n",
    "            # Get next batch data shape [B, D]\n",
    "            xb = Variable(x[step*B:step*B+B])\n",
    "            # A batch is fed through net many times (nsamples)\n",
    "            # Calculate mean of xbhat\n",
    "            xbhat = torch.zeros_like(xb)\n",
    "            for s in range(samples):\n",
    "                # perform order/connectivity-agnostic training by resampling the masks\n",
    "                if step % self.resample_every == 0 or split == 'test': # if in test, cycle masks every time\n",
    "                    self.model.update_masks()\n",
    "                # forward the model\n",
    "                xbhat += self.model(xb.float())\n",
    "            xbhat /= samples\n",
    "            \n",
    "            \n",
    "            x_recon = F.sigmoid(xbhat)\n",
    "            loss = F.mse_loss(x_recon, xb, size_average=False).div(B)\n",
    "            # Evaluate the binary cross entropy loss\n",
    "            #loss = F.binary_cross_entropy_with_logits(xbhat, xb, size_average=False) / B\n",
    "            #var = torch.ones(32, 784).cuda()\n",
    "            #loss = F.gaussian_nll_loss(xbhat, xb, var=var) #/ B\n",
    "            #lossf = loss.data.item()\n",
    "            lossfs.append(loss.cpu().detach().numpy())\n",
    "            # backward/update\n",
    "            if split == 'train':\n",
    "                self.opt.zero_grad()\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "        \n",
    "        #lossfs = np.array(lossfs)\n",
    "        mean_loss = np.mean(lossfs)\n",
    "        print(\"%s epoch loss: %f\" % (split, mean_loss))\n",
    "        return mean_loss\n",
    "\n",
    "    def draw_epoch_loss(self):\n",
    "        plt.plot(self.train_loss, label='train')\n",
    "        plt.plot(self.test_loss, label='test')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = '1024,1024'\n",
    "imgshape = (28,28)\n",
    "epochs = 75\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cz8GjXxue8xO",
    "outputId": "c78d0186-f802-4b0d-96d6-4d68a6aa681d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Dataset Binarized MNIST\n",
      "Loading data done\n",
      "------------------------------\n",
      "Constructing MADE architecture ...\n",
      "(784, 784)\n",
      "Constructing MADE architecture done\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "made = MADE(hiddens = hiddens, num_masks = 5, data = 'binmnist', ordering='raster-scan',samples = 10, \n",
    "            resample_every=40, imgshape=imgshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5ShXC84xfXsm",
    "outputId": "9bbb86a7-05c3-4ad4-b9e2-9b4c18379cb0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "made.training(epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "lWoSBVJxVCP0",
    "outputId": "917a146b-3c9d-4490-e8dd-fc843c6049e8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "made.draw_epoch_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"_\".join([str(h) for h in hiddens])\n",
    "torch.save(\n",
    "    {\n",
    "        \"epoch\": epochs,\n",
    "        \"model_state_dict\": made.model.state_dict(),\n",
    "        \"optimizer_state_dict\": made.opt.state_dict(),\n",
    "        \"scheduler_state_dict\": made.scheduler.state_dict(),\n",
    "    },\n",
    "    \"./model_vol_\" + string + \".pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"_\".join([str(h) for h in hiddens])\n",
    "\n",
    "checkpoint = torch.load(\"model_binmnist_\" + string + \".pt\")\n",
    "made.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "tot_epochs = checkpoint[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BZmtipuLCWc3"
   },
   "outputs": [],
   "source": [
    "def reconstructing(n, filename):\n",
    "    before_all, before, after = made.reconstruct(n)\n",
    "    print(before_all.shape)\n",
    "    print(before_all)\n",
    "    print(before.shape)\n",
    "    print(before)\n",
    "    print(after.shape)\n",
    "    print(after)\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    columns = 3\n",
    "    rows = n\n",
    "    for i in range(0, n):\n",
    "        fig.add_subplot(rows, columns, 3*i+1)\n",
    "        plt.imshow(before_all[i].reshape(made.imgshape).squeeze())\n",
    "        #plt.imshow(before_all[i].reshape(made.imgshape))\n",
    "        \n",
    "        fig.add_subplot(rows, columns, 3*i+2)\n",
    "        plt.imshow(before[i].reshape(made.imgshape).squeeze())\n",
    "        #plt.imshow(before[i].reshape(made.imgshape))\n",
    "        \n",
    "        fig.add_subplot(rows, columns, 3*i+3)\n",
    "        plt.imshow(after[i].reshape(made.imgshape).squeeze())\n",
    "        #plt.imshow(after[i].reshape(made.imgshape))\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "AMZEaFprkdMZ",
    "outputId": "1c4c043d-7522-42ac-f102-e8ba416e77ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 784)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(5, 784)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(5, 784)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstructing(5, \"C:\\\\Projekte\\\\dev\\\\git\\\\reconstructingx_binmnist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strikes=np.array([0.500000000000000, 0.537037037037037, 0.574074074074074, 0.611111111111111, 0.648148148148148, \n",
    "                  0.685185185185185, 0.722222222222222, 0.759259259259259, 0.796296296296296, 0.833333333333333,\n",
    "                  0.870370370370370, 0.907407407407407, 0.944444444444444, 0.981481481481481, 1.01851851851852,\n",
    "                  1.05555555555556,  1.09259259259259,  1.12962962962963,  1.16666666666667, 1.20370370370370,\n",
    "                  1.24074074074074, 1.27777777777778, 1.31481481481481, 1.35185185185185,   1.38888888888889,\n",
    "                  1.42592592592593, 1.46296296296296, 1.50000000000000])                \n",
    "\n",
    "maturities=np.array([0.500000, 0.851852, 1.203704, 1.555556, 1.907407, 2.259259, 2.611111, 2.962963, 3.314815, \n",
    "                     3.666667,4.018519, 4.370370, 4.722222, 5.074074, 5.425926, 5.777778, 6.129630, 6.481481, \n",
    "                     6.833333, 7.185185, 7.537037, 7.888889, 8.240741, 8.592593, 8.944444, 9.296296, 9.648148,\n",
    "                     10.000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "before_all, before, after = made.reconstruct(n)\n",
    "after = np.reshape(after,(n,784,1))\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "columns = 2\n",
    "rows = n\n",
    "before = np.reshape(before,(len(before),28,28,1))\n",
    "\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(strikes, maturities, before[0].reshape(made.imgshape).squeeze(), cmap=cm.coolwarm,\n",
    "                linewidth=0, antialiased=False)\n",
    "#plt.savefig('vol_original_half')   \n",
    "#   ax.plot_surface(strikes, maturities, after[i].reshape(made.imgshape).squeeze(), cmap=cm.coolwarm,\n",
    "#                      linewidth=0, antialiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5,5))\n",
    "ax = fig.gca(projection='3d')\n",
    "after = np.reshape(after,(len(after),28,28,1))\n",
    "ax.plot_surface(strikes, maturities, after[0].reshape(made.imgshape).squeeze(), cmap=cm.coolwarm,\n",
    "                linewidth=0, antialiased=False)\n",
    "#plt.savefig('vol_prop') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5,5))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(strikes, maturities, before_all[0].reshape(made.imgshape).squeeze(), cmap=cm.coolwarm,\n",
    "                linewidth=0, antialiased=False)\n",
    "#plt.savefig('vol_original') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_all[0]-(after.reshape(n,28*28)[0])\n",
    "#after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counter = np.unique(before_all[0]-(after.reshape(n,28*28)[0]), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5., device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(5.0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.loadtxt('C:\\Projekte\\dev\\git\\Masterarbeit\\\\HestonTrainSet_ivol_201_neu_groß.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9227170726870725"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MADE_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
