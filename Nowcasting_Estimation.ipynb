{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import importlib\n",
    "#Interface, Tools\n",
    "import loadData\n",
    "import plottingTools\n",
    "import factorialModel\n",
    "import teacher\n",
    "import pytorchModel\n",
    "import pytorchFwdModel\n",
    "#Interpolation\n",
    "import gaussianProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formerPath = sys.path\n",
    "sys.path.append('./Code/')\n",
    "sys.path.append('./nowcasting_torch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingFolder = \"./Data/SPX/\"\n",
    "filename = \"SPX\"\n",
    "trainingSetPercentage = 0.8\n",
    "minExpiry = -1.0\n",
    "completionRate = 0.1 #Not used anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataSet = loadData.dataSetATMPickle(workingFolder + filename, \n",
    "                                    trainingSetPercentage, \n",
    "                                    minExpiry, \n",
    "                                    completionRate, \n",
    "                                    scaleFeatures = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.datasetSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.sanityCheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataSet.getTrainingDataForModel()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.setMaskedPoints(loadData.selectLessCorrelatedFeatures(dataSet.getTrainingDataForModel()[0].corr().dropna(axis=1), 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataSet.maskDataset(dataSet.getTrainingDataForModel()[0].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plottingTools.plotGrid(dataSet.getTrainingDataForModel()[0].iloc[0],\n",
    "                       dataSet.getTrainingDataForModel()[1].iloc[0],\n",
    "                       \"First training observation\",\n",
    "                       plotType=\"transparent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "originalData = dataSet.formatModelDataAsDataSet(dataSet.getTrainingDataForModel())\n",
    "plottingTools.plotGrid(originalData[0].iloc[0],\n",
    "                       originalData[1].iloc[0],\n",
    "                       \"First training observation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_factors = 15\n",
    "nbEpochs = 10000\n",
    "nbCalibrationStep = 1000\n",
    "\n",
    "hyperparameters = {}\n",
    "hyperparameters[\"nbEpochs\"] = nbEpochs\n",
    "hyperparameters[\"verbose\"] = False\n",
    "hyperparameters[\"extrapolationMode\"] = \"NoExtrapolation\"\n",
    "hyperparameters[\"nbCalibrationStep\"] = nbCalibrationStep\n",
    "#hyperparameters[\"extrapolationMode\"] = \"InnerDomain\"\n",
    "#hyperparameters[\"extrapolationMode\"] = \"OuterDomain\"\n",
    "\n",
    "hyperparameters[\"nbX\"] = dataSet.nbMoneyness\n",
    "hyperparameters[\"nbY\"] = dataSet.nbTTM\n",
    "\n",
    "hyperparameters[\"mask\"] = dataSet.maskSerie\n",
    "\n",
    "#Penalizations\n",
    "hyperparameters[\"l2_reg\"] = 0.1\n",
    "hyperparameters[\"varianceRegularisation\"] = 1\n",
    "hyperparameters[\"extremeRegularisation\"] = 0\n",
    "hyperparameters[\"lambdaContractive\"] = 0.1\n",
    "hyperparameters[\"lambdaGaussian\"] = 1\n",
    "hyperparameters[\"lambdaCompletionEncodings\"] = 1\n",
    "hyperparameters[\"lambdaDisentangle\"] = 1.0\n",
    "hyperparameters[\"lambdaTopology\"] = 1.0\n",
    "hyperparameters[\"factorVariance\"] = 10\n",
    "hyperparameters[\"GaussianEncodings\"] = 1\n",
    "\n",
    "#Gradient descent\n",
    "hyperparameters[\"validationPercentage\"] = 0.2\n",
    "hyperparameters[\"earlyStoppingWindow\"] = 0.2\n",
    "hyperparameters[\"calibrationWindow\"] = 20\n",
    "\n",
    "hyperparameters[\"nbEpochInit\"] = 1\n",
    "hyperparameters[\"nbInit\"] = 100\n",
    "\n",
    "#Loss\n",
    "hyperparameters[\"lossHolderExponent\"] = 2\n",
    "\n",
    "#Architecture\n",
    "nbUnitsPerLayer = {}\n",
    "nbUnitsPerLayer[\"Input Layer\"] = dataSet.gridSize\n",
    "nbUnitsPerLayer[\"Output Layer\"] = nbUnitsPerLayer[\"Input Layer\"]\n",
    "nbUnitsPerLayer[\"Layer1\"] = 10\n",
    "nbUnitsPerLayer[\"Layer2\"] = 10\n",
    "nbUnitsPerLayer[\"Layer3\"] = 10\n",
    "nbUnitsPerLayer[\"Layer4\"] = 10\n",
    "\n",
    "\n",
    "nbUnitsPerLayer[\"LayerEncoder1\"] = int(dataSet.gridSize / 2)\n",
    "nbUnitsPerLayer[\"LayerEncoder2\"] = int(nbUnitsPerLayer[\"LayerEncoder1\"] / 2)\n",
    "nbUnitsPerLayer[\"LayerEncoder3\"] = int(nbUnitsPerLayer[\"LayerEncoder2\"] / 2)\n",
    "\n",
    "nbUnitsPerLayer[\"LayerDecoder1\"] = nbUnitsPerLayer[\"LayerEncoder3\"]\n",
    "nbUnitsPerLayer[\"LayerDecoder2\"] = nbUnitsPerLayer[\"LayerEncoder2\"]\n",
    "nbUnitsPerLayer[\"LayerDecoder3\"] = nbUnitsPerLayer[\"LayerEncoder1\"]\n",
    "nbUnitsPerLayer[\"LayerDEcoder4\"] = dataSet.gridSize\n",
    "\n",
    "nbChannel = 1\n",
    "hyperparameters[\"nbChannel\"] = nbChannel\n",
    "\n",
    "#Plot \n",
    "colorMapSystem = \"hsv\"\n",
    "plotType = \"transparent\"#\"flexibleWire\"\n",
    "diagnoseOriginalData = True\n",
    "\n",
    "plt.rcParams[\"animation.embed_limit\"] = 2**28\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "fps = 10\n",
    "\n",
    "#Kernel\n",
    "hyperparameters[\"bandwidthBounds\"] = (0.01, 100)\n",
    "hyperparameters[\"Train Interpolation\"] = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(teacher)\n",
    "importlib.reload(plottingTools)\n",
    "importlib.reload(pytorchModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbEpochs = 10000#10000\n",
    "nbCalibrationStep = 1000 #1000\n",
    "hyperparameters[\"nbCalibrationStep\"] = nbCalibrationStep\n",
    "hyperparameters[\"nbEpochs\"] = nbEpochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFunctional = pytorchModel.pytorchModel(learning_rate, \n",
    "                                            hyperparameters, \n",
    "                                            nbUnitsPerLayer, \n",
    "                                            n_factors)\n",
    "learningManager = teacher.Teacher(modelFunctional, \n",
    "                                  dataSet, \n",
    "                                  nbEpochs, \n",
    "                                  nbCalibrationStep)\n",
    "learningManager.diagnoseOriginalData = True\n",
    "learningManager.colorMapSystem = \"hsv\"\n",
    "learningManager.plotType = plotType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learningManager.fit(restoreResults = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learningManager.diagnoseCompression(restoreResults = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trueSurface = dataSet.getTestingDataForModel()[0].iloc[0,:]\n",
    "\n",
    "inputTmp = [dataSet.maskDataset(trueSurface),\n",
    "            dataSet.getTestingDataForModel()[1].iloc[0,:],\n",
    "            dataSet.getTestingDataForModel()[2].iloc[0,:],\n",
    "            None]\n",
    "tmp = modelFunctional.completeDataTensor(inputTmp,\n",
    "                                         learningManager.codings_Train.iloc[-1], \n",
    "                                         nbCalibrationStep)\n",
    "\n",
    "print(\"Nb Masked points : \", \n",
    "      dataSet.maskDataset(trueSurface).dropna().shape)\n",
    "\n",
    "plottingTools.plotCompletion(trueSurface, \n",
    "                             tmp[2], \n",
    "                             inputTmp[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = dataSet.maskDataset(trueSurface).dropna())\n",
    "\n",
    "res = learningManager.backTestCompletion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cache = dataSet.getDataForModel()[0].columns.difference(dataSet.maskedPoints)\n",
    "otherMaskedPoints = pd.Int64Index([92,  95, 104, 130, 131, 136, 164, 177, 178, 185, 188, 207, 208,\n",
    "                                   208, 235, 245, 257, 273, 286, 290, 307, 309, 316, 325, 326, 329,\n",
    "                                   334, 344, 367, 373, 374, 391, 392, 406, 409, 418])\n",
    "dataSet.setMaskedPoints(otherMaskedPoints)\n",
    "\n",
    "trueSurfaceOther = dataSet.getTestingDataForModel()[0].iloc[0,:]\n",
    "\n",
    "inputTmpOther = [dataSet.maskDataset(trueSurfaceOther),\n",
    "                 dataSet.getTestingDataForModel()[1].iloc[0,:],\n",
    "                 dataSet.getTestingDataForModel()[2].iloc[0,:],\n",
    "                 None]\n",
    "tmpOther = modelFunctional.completeDataTensor(inputTmpOther,\n",
    "                                              learningManager.codings_Train.iloc[-1], \n",
    "                                              nbCalibrationStep)\n",
    "\n",
    "print(\"Nb Masked points : \", \n",
    "      dataSet.maskDataset(trueSurfaceOther).dropna().shape)\n",
    "\n",
    "plottingTools.plotCompletion(trueSurfaceOther, \n",
    "                             tmpOther[2], \n",
    "                             inputTmpOther[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = dataSet.maskDataset(trueSurfaceOther).dropna())\n",
    "\n",
    "resOther = learningManager.backTestCompletion()\n",
    "\n",
    "dataSet.setMaskedPoints(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pytorchFwdModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFunctionalFwd = pytorchFwdModel.pytorchFwdModel(learning_rate, \n",
    "                                                     hyperparameters, \n",
    "                                                     nbUnitsPerLayer, \n",
    "                                                     n_factors)\n",
    "learningManager.assignNewModel(modelFunctionalFwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learningManager.fit(restoreResults = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learningManager.diagnoseCompression(restoreResults = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Real vs completed\")\n",
    "\n",
    "trueSurface = dataSet.getTestingDataForModel()[0].iloc[0,:]\n",
    "dataSet.maskDataset(trueSurface).dropna().size\n",
    "\n",
    "inputTmp = [dataSet.maskDataset(trueSurface),\n",
    "            dataSet.getTestingDataForModel()[1].iloc[0,:],\n",
    "            dataSet.getTestingDataForModel()[2].iloc[0,:],\n",
    "            None]\n",
    "tmp = modelFunctionalFwd.completeDataTensor(inputTmp,\n",
    "                                            learningManager.codings_Train.iloc[-1], \n",
    "                                            nbCalibrationStep)\n",
    "\n",
    "plottingTools.plotCompletion(trueSurface, \n",
    "                             tmp[2], \n",
    "                             inputTmp[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = dataSet.maskDataset(trueSurface).dropna())\n",
    "\n",
    "inputOutlier = [tmp[2],\n",
    "                dataSet.getTestingDataForModel()[1].iloc[0,:],\n",
    "                dataSet.getTestingDataForModel()[2].iloc[0,:],\n",
    "                None]\n",
    "tmpOutlier = modelFunctionalFwd.completeDataTensor(inputOutlier,\n",
    "                                                   pd.Series(np.zeros_like(tmp[1])), \n",
    "                                                   nbCalibrationStep)\n",
    "\n",
    "print(\"Compressed completed vs completed\")\n",
    "\n",
    "plottingTools.plotCompletion(inputOutlier[0], \n",
    "                             tmpOutlier[2], \n",
    "                             inputOutlier[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = dataSet.maskDataset(trueSurface).dropna())\n",
    "\n",
    "print(\"Compressed completed vs real\")\n",
    "plottingTools.plotCompletion(trueSurface, \n",
    "                             tmpOutlier[2], \n",
    "                             inputOutlier[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = dataSet.maskDataset(trueSurface).dropna())\n",
    "\n",
    "corruptedSurface = trueSurface.copy()\n",
    "corruptedSurface.iloc[150] = trueSurface.iloc[150] * 2\n",
    "corruptedSurface.iloc[100] = trueSurface.iloc[100] * 2\n",
    "corruptedSurface.iloc[200] = trueSurface.iloc[200] * 2\n",
    "corruptedSurface.iloc[250] = trueSurface.iloc[250] * 2\n",
    "inputCorrupted = [corruptedSurface,\n",
    "                  dataSet.getTestingDataForModel()[1].iloc[0,:],\n",
    "                  dataSet.getTestingDataForModel()[2].iloc[0,:],\n",
    "                  None]\n",
    "tmpCorrupted = modelFunctionalFwd.completeDataTensor(inputCorrupted,\n",
    "                                                     pd.Series(np.zeros_like(tmp[1])), \n",
    "                                                     nbCalibrationStep)\n",
    "\n",
    "print(\"Corrected corruption vs dummy corruption\")\n",
    "plottingTools.plotCompletion(inputCorrupted[0], \n",
    "                             tmpCorrupted[2], \n",
    "                             inputCorrupted[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = None)\n",
    "print(\"Corrected corruption vs real\")\n",
    "plottingTools.plotCompletion(trueSurface, \n",
    "                             tmpCorrupted[2], \n",
    "                             inputOutlier[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = None)\n",
    "\n",
    "res = learningManager.backTestCompletion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cache = dataSet.getDataForModel()[0].columns.difference(dataSet.maskedPoints)\n",
    "otherMaskedPoints = pd.Int64Index([92,  95, 104, 130, 131, 136, 164, 177, 178, 185, 188, 207, 208,\n",
    "                                   208, 235, 245, 257, 273, 286, 290, 307, 309, 316, 325, 326, 329,\n",
    "                                   334, 344, 367, 373, 374, 391, 392, 406, 409, 418])\n",
    "dataSet.setMaskedPoints(otherMaskedPoints)\n",
    "\n",
    "print(\"Real vs completed\")\n",
    "\n",
    "trueSurfaceOther = dataSet.getTestingDataForModel()[0].iloc[0,:]\n",
    "dataSet.maskDataset(trueSurfaceOther).dropna().size\n",
    "\n",
    "inputTmpOther = [dataSet.maskDataset(trueSurfaceOther),\n",
    "                 dataSet.getTestingDataForModel()[1].iloc[0,:],\n",
    "                 dataSet.getTestingDataForModel()[2].iloc[0,:],\n",
    "                 None]\n",
    "tmpOther = modelFunctionalFwd.completeDataTensor(inputTmpOther,\n",
    "                                                 learningManager.codings_Train.iloc[-1], \n",
    "                                                 nbCalibrationStep)\n",
    "\n",
    "plottingTools.plotCompletion(trueSurfaceOther, \n",
    "                             tmpOther[2], \n",
    "                             inputTmpOther[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = dataSet.maskDataset(trueSurfaceOther).dropna())\n",
    "\n",
    "inputOutlierOther = [tmpOther[2],\n",
    "                     dataSet.getTestingDataForModel()[1].iloc[0,:],\n",
    "                     dataSet.getTestingDataForModel()[2].iloc[0,:],\n",
    "                     None]\n",
    "tmpOutlierOther = modelFunctionalFwd.completeDataTensor(inputOutlierOther,\n",
    "                                                        pd.Series(np.zeros_like(tmpOther[1])), \n",
    "                                                        nbCalibrationStep)\n",
    "\n",
    "print(\"Compressed completed vs completed\")\n",
    "\n",
    "plottingTools.plotCompletion(inputOutlierOther[0], \n",
    "                             tmpOutlierOther[2], \n",
    "                             inputOutlierOther[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = dataSet.maskDataset(trueSurfaceOther).dropna())\n",
    "\n",
    "print(\"Compressed completed vs real\")\n",
    "plottingTools.plotCompletion(trueSurfaceOther, \n",
    "                             tmpOutlierOther[2], \n",
    "                             inputOutlierOther[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = dataSet.maskDataset(trueSurfaceOther).dropna())\n",
    "\n",
    "corruptedSurfaceOther = trueSurfaceOther.copy()\n",
    "corruptedSurfaceOther.iloc[150] = trueSurfaceOther.iloc[150] * 2\n",
    "corruptedSurfaceOther.iloc[100] = trueSurfaceOther.iloc[100] * 2\n",
    "corruptedSurfaceOther.iloc[200] = trueSurfaceOther.iloc[200] * 2\n",
    "corruptedSurfaceOther.iloc[250] = trueSurfaceOther.iloc[250] * 2\n",
    "inputCorruptedOther = [corruptedSurfaceOther,\n",
    "                       dataSet.getTestingDataForModel()[1].iloc[0,:],\n",
    "                       dataSet.getTestingDataForModel()[2].iloc[0,:],\n",
    "                       None]\n",
    "tmpCorruptedOther = modelFunctionalFwd.completeDataTensor(inputCorruptedOther,\n",
    "                                                          pd.Series(np.zeros_like(tmpOther[1])), \n",
    "                                                          nbCalibrationStep)\n",
    "\n",
    "print(\"Corrected corruption vs dummy corruption\")\n",
    "plottingTools.plotCompletion(inputCorruptedOther[0], \n",
    "                             tmpCorruptedOther[2], \n",
    "                             inputCorruptedOther[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = None)\n",
    "print(\"Corrected corruption vs real\")\n",
    "plottingTools.plotCompletion(trueSurfaceOther, \n",
    "                             tmpCorruptedOther[2], \n",
    "                             inputOutlierOther[1],\n",
    "                             colorMapSystem=learningManager.colorMapSystem, \n",
    "                             plotType=learningManager.plotType,\n",
    "                             refPoints = None)\n",
    "\n",
    "thetaSurface = modelFunctionalFwd.getArbitrageTheta(inputCorruptedOther, \n",
    "                                                    pd.Series(tmpCorruptedOther[1]))\n",
    "plottingTools.plotGrid(thetaSurface.iloc[0],\n",
    "                       inputCorruptedOther[1],    \n",
    "                       \"Calendar condition for worst reconstruction on testing dataset\", \n",
    "                       colorMapSystem=learningManager.colorMapSystem, \n",
    "                       plotType=learningManager.plotType,\n",
    "                       refPoints = None,\n",
    "                       zLabelUser = \"Implied total variance Theta\")\n",
    "\n",
    "resOther = learningManager.backTestCompletion()\n",
    "\n",
    "dataSet.setMaskedPoints(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaSurface.min().min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInterpolationLinear = gaussianProcess.LinearInterpolation(learning_rate, \n",
    "                                                               hyperparameters, \n",
    "                                                               nbUnitsPerLayer, \n",
    "                                                               n_factors)\n",
    "learningManager.assignNewModel(modelInterpolationLinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningManager.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learningManager.diagnoseCompression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = learningManager.backTestCompletion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = dataSet.getDataForModel()[0].columns.difference(dataSet.maskedPoints)\n",
    "otherMaskedPoints = pd.Int64Index([92,  95, 104, 130, 131, 136, 164, 177, 178, 185, 188, 207, 208,\n",
    "                                   208, 235, 245, 257, 273, 286, 290, 307, 309, 316, 325, 326, 329,\n",
    "                                   334, 344, 367, 373, 374, 391, 392, 406, 409, 418])\n",
    "dataSet.setMaskedPoints(otherMaskedPoints)\n",
    "res = learningManager.backTestCompletion()\n",
    "dataSet.setMaskedPoints(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInterpolationSpline = gaussianProcess.SplineInterpolation(learning_rate, \n",
    "                                                               hyperparameters, \n",
    "                                                               nbUnitsPerLayer, \n",
    "                                                               n_factors)\n",
    "learningManager.assignNewModel(modelInterpolationSpline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningManager.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learningManager.diagnoseCompression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cache = dataSet.getDataForModel()[0].columns.difference(dataSet.maskedPoints)\n",
    "otherMaskedPoints = pd.Int64Index([92,  95, 104, 130, 131, 136, 164, 177, 178, 185, 188, 207, 208,\n",
    "                                   208, 235, 245, 257, 273, 286, 290, 307, 309, 316, 325, 326, 329,\n",
    "                                   334, 344, 367, 373, 374, 391, 392, 406, 409, 418])\n",
    "dataSet.setMaskedPoints(otherMaskedPoints)\n",
    "res = learningManager.backTestCompletion()\n",
    "dataSet.setMaskedPoints(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGaussianProcessNoExtrapolation = gaussianProcess.GaussianProcess(learning_rate, \n",
    "                                                                      hyperparameters, \n",
    "                                                                      nbUnitsPerLayer, \n",
    "                                                                      n_factors)\n",
    "learningManager.assignNewModel(modelGaussianProcessNoExtrapolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningManager.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningManager.diagnoseCompression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = learningManager.backTestCompletion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = dataSet.getDataForModel()[0].columns.difference(dataSet.maskedPoints)\n",
    "otherMaskedPoints = pd.Int64Index([92,  95, 104, 130, 131, 136, 164, 177, 178, 185, 188, 207, 208,\n",
    "                                   208, 235, 245, 257, 273, 286, 290, 307, 309, 316, 325, 326, 329,\n",
    "                                   334, 344, 367, 373, 374, 391, 392, 406, 409, 418])\n",
    "dataSet.setMaskedPoints(otherMaskedPoints)\n",
    "res = learningManager.backTestCompletion()\n",
    "dataSet.setMaskedPoints(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters[\"extrapolationMode\"] = \"OuterDomain\"\n",
    "modelGaussianProcessOuterExtrapolation = gaussianProcess.GaussianProcess(learning_rate, \n",
    "                                                                         hyperparameters, \n",
    "                                                                         nbUnitsPerLayer, \n",
    "                                                                         n_factors)\n",
    "learningManager.assignNewModel(modelGaussianProcessOuterExtrapolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningManager.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningManager.diagnoseCompression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = learningManager.backTestCompletion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = dataSet.getDataForModel()[0].columns.difference(dataSet.maskedPoints)\n",
    "otherMaskedPoints = pd.Int64Index([92,  95, 104, 130, 131, 136, 164, 177, 178, 185, 188, 207, 208,\n",
    "                                   208, 235, 245, 257, 273, 286, 290, 307, 309, 316, 325, 326, 329,\n",
    "                                   334, 344, 367, 373, 374, 391, 392, 406, 409, 418])\n",
    "dataSet.setMaskedPoints(otherMaskedPoints)\n",
    "res = learningManager.backTestCompletion()\n",
    "dataSet.setMaskedPoints(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters[\"extrapolationMode\"] = \"NoExtrapolation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters[\"extrapolationMode\"] = \"InnerDomain\"\n",
    "modelGaussianProcessInnerExtrapolation = gaussianProcess.GaussianProcess(learning_rate, \n",
    "                                                                         hyperparameters, \n",
    "                                                                         nbUnitsPerLayer, \n",
    "                                                                         n_factors)\n",
    "learningManager.assignNewModel(modelGaussianProcessInnerExtrapolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningManager.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningManager.diagnoseCompression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = learningManager.backTestCompletion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = dataSet.getDataForModel()[0].columns.difference(dataSet.maskedPoints)\n",
    "otherMaskedPoints = pd.Int64Index([92,  95, 104, 130, 131, 136, 164, 177, 178, 185, 188, 207, 208,\n",
    "                                   208, 235, 245, 257, 273, 286, 290, 307, 309, 316, 325, 326, 329,\n",
    "                                   334, 344, 367, 373, 374, 391, 392, 406, 409, 418])\n",
    "dataSet.setMaskedPoints(otherMaskedPoints)\n",
    "res = learningManager.backTestCompletion()\n",
    "dataSet.setMaskedPoints(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters[\"extrapolationMode\"] = \"NoExtrapolation\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
